{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from mistralai import Mistral  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../src\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST http://localhost:8800/general/v0/general \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table><tr><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td><td>Luz Adriana Pinto Diaz</td></tr><tr><td>luzadriana.pin@gmail.com</td><td>+49 17637264922</td><td>+49 17637264922</td><td>+49 17637264922</td><td>+49 17637264922</td><td>linkedin.com/in/luzadrianapinto</td><td>linkedin.com/in/luzadrianapinto</td><td>linkedin.com/in/luzadrianapinto</td><td>linkedin.com/in/luzadrianapinto</td></tr><tr><td/><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>github.com/adrianapintod</td><td>github.com/adrianapintod</td><td>github.com/adrianapintod</td><td>github.com/adrianapintod</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td><td>WORK EXPERIENCE</td></tr><tr><td>eGroup</td><td>eGroup</td><td>eGroup</td><td>eGroup</td><td>eGroup</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td></tr><tr><td>AI Engineer</td><td>AI Engineer</td><td>AI Engineer</td><td>AI Engineer</td><td>AI Engineer</td><td>October 2024 - Present</td><td>October 2024 - Present</td><td>October 2024 - Present</td><td>October 2024 - Present</td></tr><tr><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td><td>Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests. Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks. Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes. Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications. Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic. Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.</td></tr><tr><td>Amazon</td><td>Amazon</td><td>Amazon</td><td>Amazon</td><td>Amazon</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td></tr><tr><td>Business Intelligence Engineer</td><td>Business Intelligence Engineer</td><td>Business Intelligence Engineer</td><td>Business Intelligence Engineer</td><td>Business Intelligence Engineer</td><td>June 2022 - September 2024</td><td>June 2022 - September 2024</td><td>June 2022 - September 2024</td><td>June 2022 - September 2024</td></tr><tr><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td><td>Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark. Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies. Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability. Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight. Guide and support business users to identify their data needs. Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.</td></tr><tr><td>Amazon</td><td>Amazon</td><td>Amazon</td><td>Amazon</td><td>Amazon</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td><td>Berlin, Germany</td></tr><tr><td>Business Intelligence Engineer Intern</td><td>Business Intelligence Engineer Intern</td><td>Business Intelligence Engineer Intern</td><td>Business Intelligence Engineer Intern</td><td>Business Intelligence Engineer Intern</td><td>March 2021 - August 2021</td><td>March 2021 - August 2021</td><td>March 2021 - August 2021</td><td>March 2021 - August 2021</td></tr><tr><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td><td>Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas. Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing. Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings. Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions. Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.</td></tr><tr><td>PayU Latam</td><td>PayU Latam</td><td>PayU Latam</td><td>PayU Latam</td><td>PayU Latam</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td></tr><tr><td>Integration and Support Engineer</td><td>Integration and Support Engineer</td><td>Integration and Support Engineer</td><td>Integration and Support Engineer</td><td>Integration and Support Engineer</td><td>May 2015 – October 2015</td><td>May 2015 – October 2015</td><td>May 2015 – October 2015</td><td>May 2015 – October 2015</td></tr><tr><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td><td>Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript. Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.</td></tr><tr><td>Innovatek/Abbott Informatics</td><td>Innovatek/Abbott Informatics</td><td>Innovatek/Abbott Informatics</td><td>Innovatek/Abbott Informatics</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td><td>Bogota, Colombia</td></tr><tr><td>Configuration Engineer</td><td>Configuration Engineer</td><td>Configuration Engineer</td><td>Configuration Engineer</td><td>November 2013 – April 2015</td><td>November 2013 – April 2015</td><td>November 2013 – April 2015</td><td>November 2013 – April 2015</td><td>November 2013 – April 2015</td></tr><tr><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td><td>Implement and customize LIMS (Software for Laboratory Information Management) for customers. Develop custom features using SSL (Starlims Scripting Language) based on .NET. Build reports harnessing SAP Crystal Reports to support lab analytics needs. Collaborate with project managers to gather functional requirements from stakeholders. Train and support LIMS end users.</td></tr><tr><td>Cerrejon</td><td>Cerrejon</td><td>Cerrejon</td><td>La Guajira, Colombia</td><td>La Guajira, Colombia</td><td>La Guajira, Colombia</td><td>La Guajira, Colombia</td><td>La Guajira, Colombia</td><td>La Guajira, Colombia</td></tr><tr><td>Systems Engineering Intern</td><td>Systems Engineering Intern</td><td>Systems Engineering Intern</td><td>June 2012 – December 2012</td><td>June 2012 – December 2012</td><td>June 2012 – December 2012</td><td>June 2012 – December 2012</td><td>June 2012 – December 2012</td><td>June 2012 – December 2012</td></tr><tr><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td><td>Develop internal application for inventory management. Create data reports with SQLServer and SAP Business Objects.</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>EDUCATION</td><td>EDUCATION</td><td>EDUCATION</td><td>EDUCATION</td><td>EDUCATION</td><td/><td/><td/><td/></tr><tr><td>Freie Unversität Berlin</td><td>Freie Unversität Berlin</td><td>Freie Unversität Berlin</td><td>Freie Unversität Berlin</td><td>Freie Unversität Berlin</td><td>Freie Unversität Berlin</td><td/><td/><td/></tr><tr><td>Master of Science in Computer Science</td><td>Master of Science in Computer Science</td><td>Master of Science in Computer Science</td><td>Master of Science in Computer Science</td><td>Master of Science in Computer Science</td><td>Master of Science in Computer Science</td><td/><td/><td/></tr><tr><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td>Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)</td><td/></tr><tr><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td>Create a computer vision garments classification model using a meta-learning approach on Tensorflow to classify novel clothing categories having only a few labelled examples. Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.</td><td/></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td><td>Universidad Industrial de Santander</td></tr><tr><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td><td>Bachelor of Science in Systems Engineering</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td><td>HONORS &amp; AWARDS</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>Berlin MLOps Community Hackathon (Winner)</td><td>Berlin MLOps Community Hackathon (Winner)</td><td>Berlin MLOps Community Hackathon (Winner)</td><td>June 2023</td><td>June 2023</td><td>June 2023</td><td>June 2023</td><td>June 2023</td><td>June 2023</td></tr><tr><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td>Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools. The hackathon wrap-up can be found here.</td><td/></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>COURSES</td><td>COURSES</td><td>COURSES</td><td>COURSES</td><td>COURSES</td><td>COURSES</td><td>COURSES</td><td>COURSES</td><td>COURSES</td></tr><tr><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td><td>Fourth Brain Machine Learning Academy backed by Andrew NG.</td></tr><tr><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td><td>Machine Learning Engineering Certification</td></tr><tr><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td><td>Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as Tensorflow and Pytorch. Deploy and productionize machine learning models trough REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines. Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td><td>LANGUAGES</td></tr><tr><td/><td/><td/><td/><td/><td/><td/><td/><td/></tr><tr><td>Spanish: native language English: fluent (speaking, reading, writing) German: advanced (C1)</td><td>Spanish: native language English: fluent (speaking, reading, writing) German: advanced (C1)</td><td/><td/><td/><td/><td/><td/><td/></tr></table>\n"
     ]
    }
   ],
   "source": [
    "from unstructured_client import UnstructuredClient\n",
    "\n",
    "unstructured_api_key = os.getenv(\"UNSTRUCTURED_API_KEY\")\n",
    "with UnstructuredClient(\n",
    "    api_key_auth=unstructured_api_key,\n",
    "    server_url=\"http://localhost:8800/general/v0/general\",\n",
    ") as client:\n",
    "    res = client.general.partition(\n",
    "        request={\n",
    "            \"partition_parameters\": {\n",
    "                \"files\": {\n",
    "                    \"content\": open(\"../data/input/resume.docx\", \"rb\"),\n",
    "                    \"file_name\": \"resume.docx\",\n",
    "                },\n",
    "            },\n",
    "        },\n",
    "    )\n",
    "\n",
    "print(res.elements[0][\"metadata\"][\"text_as_html\"])\n",
    "\n",
    "resume = res.elements[0][\"metadata\"][\"text_as_html\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = \"Volkswagen Group Services is excited to present a fantastic opportunity to join our Volkswagen Digital:Hub in Spain. As part of the global Software Development Centre network in the Volkswagen Group, we constantly seek talented individuals ready to bring their unique skills to our projects.\\nOur start-up environment is collaborative, innovative, and open to new ideas. We strive to cultivate a work culture that encourages individual growth, team empowerment, and project excellence. We value respect, teamwork, and the common purpose that binds us as a group. If you're ready to thrive in a dynamic start-up environment and be part of our family, supported by one of the largest companies in the world, we invite you to read further.\\nAbout the Team and the Hub:Our culture is centered around fostering individual growth and team empowerment within a flexible and supportive environment.We prioritize respect, teamwork, and inclusivity, recognizing and valuing the unique contributions of each member.We embrace a work-life balance philosophy and encourage continuous personal and professional development.\\nThe Role and Key Responsibilities:To anticipate, identify and eliminate blockers in the team.Ensure Guidelines, Best Practices and Architecture.Delivery Advocate & Enabler.Responsible of sharing the knowledge and the team agreements between the team.You will work on a day-to-day basis with our design, frontend, backend and testing team to build a scalable and solid product.Working using best practices (testing, code reviews, DDD, CI/CD, clean cose...) and Agile methodologies.Collaborate in the design of the cluster architecture.Create of new automated tests/alerts.Analysis of new functionalities/system improvements.Dev ops: Pipeline's maintenance, creation // Deployment configuration maintenance, creation.\\nRequirements:BA Degree in Computer Sciences (or FP) and/or professional experience in Software.Software engineering background.At least 5 years of experience and 2 doing this role.Good management skills and team spirit.Experience with Java and Spring ecosystem, Spring boot, Go is a plus or another languages.Experience with testing tools like: Jest, Cypress, Testing library..Experience with AWS; AWS Glue, AWS Lambda, AWS CloudFormation Service, AWS Cloudwatch Service, AWS DynamoDB Service, AWS VPC (Amazon Virtual Private)...Experience with REST APIs.Experience with Azure Cloud.DevOps knowledge (Kubernetes, Azure DevOps)Fluent English and/or Spanish speakerFluent German speaker (nice to have)\\nWhat we offer:Fully remote work capability, with an option to work from our office when needed.Access to professional development tools and free language courses.Flexible working hours to accommodate personal and professional needs.A competitive holiday package and access to a variety of employee discounts.\\n\\nJoin us at Volkswagen Digital:Hub to advance your career in a role where your administrative skills will directly contribute to the success and smooth operation of our innovative projects.\\nFor more information on our data processing activities and your rights as a data subject, please consult our privacy policy.\\nRef: Level C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(contents))\n\u001b[1;32m     45\u001b[0m dict_contents \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(contents)\n\u001b[0;32m---> 47\u001b[0m customized_resume \u001b[38;5;241m=\u001b[39m \u001b[43mcontents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresume\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     48\u001b[0m changes \u001b[38;5;241m=\u001b[39m contents[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchanges\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "api_key = os.getenv(\"MISTRAL_API_KEY\")\n",
    "model = \"mistral-large-latest\"\n",
    "\n",
    "mistral_client = Mistral(api_key=api_key)\n",
    "\n",
    "chat_response = mistral_client.chat.complete(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"You are a helpful assistant that helps user optimize their resume for a job description.\n",
    "                    You will be given a CV and a job description and you have to do the following tasks:\n",
    "                     - You have to update the resume so that it fits better to the position from the job description.\n",
    "                     - Feel free to add new bullet points if necessary to the work experience, to better match the job description.\n",
    "                     - Your output should be a JSON object with the following fields:\n",
    "                        - \"resume\": the customized resume including the key changes made in markdown format.\n",
    "                        - \"changes\": a list of the key changes made to the resume.\n",
    "                    For this task, I will be paying a tip above 1000% if you do a good job.\n",
    "                    My professional career fully depends on you, so please do your best.\"\"\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"Here is the CV:\n",
    "            <cv>\n",
    "            {resume}\n",
    "            </cv>\n",
    "            Here is the job description:\n",
    "            <job_description>\n",
    "            {job_description}\n",
    "            </job_description>\"\"\".format(\n",
    "                resume=resume,\n",
    "                job_description=job_description,\n",
    "            ),\n",
    "        },\n",
    "    ],\n",
    "    response_format={\n",
    "        \"type\": \"json_object\",\n",
    "    },\n",
    ")\n",
    "\n",
    "contents = chat_response.choices[0].message.content\n",
    "print(type(contents))\n",
    "dict_contents = json.loads(contents)\n",
    "\n",
    "customized_resume = contents[\"resume\"]\n",
    "changes = contents[\"changes\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resume': '## Luz Adriana Pinto Diaz\\n\\n**Contact Information**\\n\\n- Email: [luzadriana.pin@gmail.com](mailto:luzadriana.pin@gmail.com)\\n- Phone: +49 17637264922\\n- Location: Berlin, Germany\\n- LinkedIn: [linkedin.com/in/luzadrianapinto](http://linkedin.com/in/luzadrianapinto)\\n- GitHub: [github.com/adrianapintod](http://github.com/adrianapintod)\\n\\n## Work Experience\\n\\n### AI Engineer | eGroup | Berlin, Germany | October 2024 - Present\\n\\n- Design and develop Python-based solutions using LLMs with the LangChain framework, integrated with vector databases such as Weaviate and FAISS, to enhance the efficiency of call center agents in handling daily assistance requests.\\n- Build AI workflows with RabbitMQ and Temporal, ensuring a robust and fault-tolerant architecture for handling long-running asynchronous tasks.\\n- Implement Docker and Docker Compose to support local development, providing isolated environments for all existing services and tools to ensure consistent integration and development processes.\\n- Create REST APIs using FastAPI to provide easy access to services and support seamless integration with other systems and applications.\\n- Ensure high quality and consistent code by implementing advanced typing in Python with Pydantic.\\n- Plan and prioritize tasks and deliverables, provide regular progress updates to stakeholders, and track and manage work effectively using Jira.\\n- **New**: Collaborate with cross-functional teams (design, frontend, backend, and testing) to build scalable and solid products using best practices such as testing, code reviews, DDD, CI/CD, and clean code.\\n- **New**: Contribute to the design of cluster architecture and create new automated tests/alerts.\\n- **New**: Analyze new functionalities and system improvements, maintaining and creating deployment configurations and pipelines.\\n\\n### Business Intelligence Engineer | Amazon | Berlin, Germany | June 2022 - September 2024\\n\\n- Create, maintain, and optimize ETL pipelines for business analytics using SQL, Redshift, Athena, Glue, and Spark.\\n- Develop outlier detection solutions based on structured data using statistical and machine learning techniques to identify operational anomalies.\\n- Design and deploy serverless architectures on AWS to run business intelligence solutions efficiently, utilizing Lambda functions, S3, AWS Step Functions, and AWS Event Bridge, ensuring scalability.\\n- Work effectively with various stakeholders to optimize processes by creating reporting tools and visualizations using SQL, Python, Tableau, and AWS QuickSight.\\n- Guide and support business users to identify their data needs.\\n- Manage project timelines and priorities and coordinate deliverables to guarantee on-time completion of business intelligence solutions.\\n- **New**: Experience with AWS services such as AWS Glue, AWS Lambda, AWS CloudFormation Service, AWS CloudWatch Service, AWS DynamoDB Service, and AWS VPC.\\n\\n### Business Intelligence Engineer Intern | Amazon | Berlin, Germany | March 2021 - August 2021\\n\\n- Develop an anomaly detection model using Python, AWS SageMaker, and S3 to surface operational risk areas.\\n- Conduct exploratory analysis with Pandas and Matplotlib on structured data to discover suspicious activities supporting internal auditing.\\n- Collaborate with risk and compliance team to validate ML model results and improve its performance based on audit findings.\\n- Deliver a risk and compliance report built in AWS QuickSight with actionable and value-added recommendations to support corrective actions.\\n- Train business users on basic SQL skills, enabling them to create self-service metrics and perform data extraction.\\n\\n### Integration and Support Engineer | PayU Latam | Bogota, Colombia | May 2015 – October 2015\\n\\n- Assist customers with the integration of the PayU online payment platform into e-commerce websites and mobile applications, using: PHP, REST API, Java, and JavaScript.\\n- Maintain the website hosting the technical documentation for customers to integrate with the online payment platform.\\n\\n### Configuration Engineer | Innovatek/Abbott Informatics | Bogota, Colombia | November 2013 – April 2015\\n\\n- Implement and customize LIMS (Software for Laboratory Information Management) for customers.\\n- Develop custom features using SSL (Starlims Scripting Language) based on .NET.\\n- Build reports harnessing SAP Crystal Reports to support lab analytics needs.\\n- Collaborate with project managers to gather functional requirements from stakeholders.\\n- Train and support LIMS end users.\\n\\n### Systems Engineering Intern | Cerrejon | La Guajira, Colombia | June 2012 – December 2012\\n\\n- Develop internal application for inventory management.\\n- Create data reports with SQLServer and SAP Business Objects.\\n\\n## Education\\n\\n### Master of Science in Computer Science | Freie Universität Berlin\\n\\n- Thesis topic: Classification of unseen garments through few-shot learning for garment sorting processes. Grade 1,0 (German grading system)\\n- Create a computer vision garments classification model using a meta-learning approach on TensorFlow to classify novel clothing categories having only a few labeled examples.\\n- Build a machine learning pipeline using Docker, Kubeflow, and CI/CD tools such as GitHub Actions, automating the end-to-end model lifecycle.\\n\\n### Bachelor of Science in Systems Engineering | Universidad Industrial de Santander\\n\\n## Honors & Awards\\n\\n### Berlin MLOps Community Hackathon (Winner) | June 2023\\n\\n- Our team won 1st place with “Cine Scripter” in the “Vector DB and Large Language Models (LLM) hackathon”: what can you build with a dataset, large language models, and vector database in a day? Cine Scripter is an application to generate video content based on own data using GPT-4, Weaviate vector database, and third-party voice, multimedia, and text generation tools.\\n\\n## Courses\\n\\n### Fourth Brain Machine Learning Academy backed by Andrew NG | Machine Learning Engineering Certification\\n\\n- Receive training in: Build, validate, and test supervised, unsupervised, and semi-supervised machine learning models using machine/deep learning frameworks such as TensorFlow and PyTorch.\\n- Deploy and productionize machine learning models through REST APIs in cloud environments (AWS and GCP) harnessing CI/CD pipelines.\\n- Machine learning infrastructure and tooling such as MLFlow, Databricks, and SageMaker.\\n\\n## Languages\\n\\n- Spanish: native language\\n- English: fluent (speaking, reading, writing)\\n- German: advanced (C1)\\n', 'changes': ['Added collaboration with cross-functional teams to build scalable products using best practices.', 'Included contribution to the design of cluster architecture and creation of new automated tests/alerts.', 'Added analysis of new functionalities and system improvements, maintaining and creating deployment configurations and pipelines.', 'Highlighted experience with AWS services such as AWS Glue, AWS Lambda, AWS CloudFormation Service, AWS CloudWatch Service, AWS DynamoDB Service, and AWS VPC.', 'Emphasized experience with REST APIs, Azure Cloud, and DevOps knowledge (Kubernetes, Azure DevOps).']}\n"
     ]
    }
   ],
   "source": [
    "print(dict_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from md2pdf.core import md2pdf\n",
    "\n",
    "pdf = \"../data/customized_resume.pdf\"\n",
    "md2pdf(\n",
    "    pdf_file_path=pdf,\n",
    "    md_content=customized_resume,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
